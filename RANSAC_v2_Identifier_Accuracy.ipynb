{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/roshankenia/RANSAC/blob/main/RANSAC_v2_Identifier_Accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J4OBdO89fJqZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"   #(xxxx is your specific GPU ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ({'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'APPDATA': 'C:\\\\Users\\\\kenia\\\\AppData\\\\Roaming', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'COMPUTERNAME': 'DESKTOP-PI2Q793', 'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe', 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\kenia', 'INTELLIJ IDEA COMMUNITY EDITION': 'C:\\\\Program Files\\\\JetBrains\\\\IntelliJ IDEA Community Edition 2021.2.3\\\\bin;', 'LOCALAPPDATA': 'C:\\\\Users\\\\kenia\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\DESKTOP-PI2Q793', 'NUMBER_OF_PROCESSORS': '4', 'ONEDRIVE': 'C:\\\\Users\\\\kenia\\\\OneDrive', 'ONEDRIVECONSUMER': 'C:\\\\Users\\\\kenia\\\\OneDrive', 'OS': 'Windows_NT', 'PATH': 'C:\\\\Program Files\\\\Python39\\\\Scripts\\\\;C:\\\\Program Files\\\\Python39\\\\;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files\\\\Microsoft VS Code\\\\bin;C:\\\\Program Files\\\\nodejs\\\\;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\ISC BIND 9\\\\bin;C:\\\\Program Files\\\\PuTTY\\\\;C:\\\\Program Files\\\\Python35\\\\python.exe;C:\\\\Users\\\\kenia\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin;C:\\\\Program Files\\\\heroku\\\\bin;C:\\\\Users\\\\kenia\\\\AppData\\\\Roaming\\\\npm;C:\\\\Users\\\\kenia\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\Scripts', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW;.CPL', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 69 Stepping 1, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROCESSOR_REVISION': '4501', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES': 'C:\\\\Program Files', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PROGRAMW6432': 'C:\\\\Program Files', 'PSMODULEPATH': 'C:\\\\Users\\\\kenia\\\\Documents\\\\WindowsPowerShell\\\\Modules;C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules', 'PUBLIC': 'C:\\\\Users\\\\Public', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\WINDOWS', 'TEMP': 'C:\\\\Users\\\\kenia\\\\AppData\\\\Local\\\\Temp', 'TMP': 'C:\\\\Users\\\\kenia\\\\AppData\\\\Local\\\\Temp', 'USERDOMAIN': 'DESKTOP-PI2Q793', 'USERDOMAIN_ROAMINGPROFILE': 'DESKTOP-PI2Q793', 'USERNAME': 'kenia', 'USERPROFILE': 'C:\\\\Users\\\\kenia', 'WINDIR': 'C:\\\\WINDOWS', 'WSLENV': 'WT_SESSION::WT_PROFILE_ID', 'WT_PROFILE_ID': '{61c54bbd-c2c6-5271-96e7-009a87ff44bf}', 'WT_SESSION': '2bafb3dd-dfea-4beb-9fd3-d526fc16e6db', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'JPY_INTERRUPT_EVENT': '1632', 'IPY_INTERRUPT_EVENT': '1632', 'JPY_PARENT_PID': '2524', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'CUDA_DEVICE_ORDER': 'PCI_BUS_ID', 'CUDA_VISIBLE_DEVICES': '6'})\n"
     ]
    }
   ],
   "source": [
    "print(os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (2.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\program files\\python39\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.20.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python39\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\program files\\python39\\lib\\site-packages (from tensorflow) (1.22.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xFZGJdFrzM4Y"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Conv2D, GlobalMaxPooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_59iWYm35NI1"
   },
   "outputs": [],
   "source": [
    "#method to add noisy labels to data\n",
    "def corruptData(trainY, testY, noisePercentage):\n",
    "  #create copies of labels\n",
    "  copyTrainY = trainY.copy()\n",
    "  copyTestY = testY.copy()\n",
    "\n",
    "  #calculate number of samples to be made noisy\n",
    "  numberNoisyTrain = int(noisePercentage * len(copyTrainY))\n",
    "  numberNoisyTest = int(noisePercentage * len(copyTestY))\n",
    "\n",
    "  #generate indexes to swap\n",
    "  trainYSwitchIndexes = random.sample(range(0, len(copyTrainY)), numberNoisyTrain)\n",
    "  testYSwitchIndexes = random.sample(range(0, len(copyTestY)), numberNoisyTest)\n",
    "\n",
    "  #generate new classes not equal to original for training and switch class\n",
    "  for i in range(len(trainYSwitchIndexes)):\n",
    "    label = random.choice(range(10))\n",
    "    #find label that isn't the same\n",
    "    while label == trainY[trainYSwitchIndexes[i]]:\n",
    "      label = random.choice(range(10))\n",
    "    #switch label\n",
    "    copyTrainY[trainYSwitchIndexes[i]] = label\n",
    "\n",
    "  #generate new classes not equal to original for testing and switch class\n",
    "  for i in range(len(testYSwitchIndexes)):\n",
    "    label = random.choice(range(10))\n",
    "    #find label that isn't the same\n",
    "    while label == testY[testYSwitchIndexes[i]]:\n",
    "      label = random.choice(range(10))\n",
    "    #switch label\n",
    "    copyTestY[testYSwitchIndexes[i]] = label\n",
    "\n",
    "  return (copyTrainY, copyTestY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "A45ilUoz7ME_"
   },
   "outputs": [],
   "source": [
    "def splitTrainingData(trainX, trainY, splitPercentage):\n",
    "  #get number of elements to split\n",
    "  numberSplit = int(splitPercentage * len(trainX))\n",
    "  #generate indexes to split\n",
    "  indexes = list(range(len(trainX)))\n",
    "  beforeSplitIndexes = random.sample(range(0, len(trainX)), numberSplit)\n",
    "  afterSplitIndexes = list(set(indexes)-set(beforeSplitIndexes))\n",
    "\n",
    "  #make new arrays\n",
    "  firstTrainX = []\n",
    "  firstTrainY = []\n",
    "  secondTrainX = []\n",
    "  secondTrainY = []\n",
    "\n",
    "  #add each data sample to corresponding list\n",
    "  for index in beforeSplitIndexes:\n",
    "    firstTrainX.append(trainX[index])\n",
    "    firstTrainY.append(trainY[index])\n",
    "  for index in afterSplitIndexes:\n",
    "    secondTrainX.append(trainX[index])\n",
    "    secondTrainY.append(trainY[index])      \n",
    "  return np.array(firstTrainX), np.array(firstTrainY), np.array(secondTrainX), np.array(secondTrainY), beforeSplitIndexes, afterSplitIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iP62iA_4rP-r"
   },
   "outputs": [],
   "source": [
    "def trainModel(trainX, trainY, n):\n",
    "  #pre-train the model\n",
    "\n",
    "  # number of classes\n",
    "  K = 10\n",
    "\n",
    "  # calculate total number of classes\n",
    "  # for output layer\n",
    "  print(\"number of classes:\", K)\n",
    "\n",
    "  # Build the model using the functional API\n",
    "  # input layer\n",
    "  i = Input(shape=trainX[0].shape)\n",
    "  x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  if n == 2:\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  if n == 3:\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = Flatten()(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "\n",
    "  # Hidden layer\n",
    "  x = Dense(1024, activation='relu')(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "\n",
    "  # last hidden layer i.e.. output layer\n",
    "  x = Dense(K, activation='softmax')(x)\n",
    "\n",
    "  model = Model(i, x)\n",
    "\n",
    "  # model description\n",
    "  # model.summary()\n",
    "\n",
    "  # Compile\n",
    "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  # Fit\n",
    "  r = model.fit(trainX, trainY, epochs=20)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\users\\kenia\\appdata\\roaming\\python\\python39\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in c:\\program files\\python39\\lib\\site-packages (from scipy) (1.22.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pBctT4ppc8_W"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "def makeConfidentTrainingSets(model, firstTrainX, firstTrainY, secondTrainX, secondTrainY, perEntropy, perPeak, beforeSplitIndexes, afterSplitIndexes):\n",
    "  newTrainX=[]\n",
    "  newTrainY=[]\n",
    "  confidentIndexes = []\n",
    "  #find confident samples from first training set\n",
    "  #obtain probability distribution of classes for each sample after the split and calculate its entropy\n",
    "  #make predictions\n",
    "  firstTrainXPredictions = model.predict(firstTrainX)\n",
    "  #find entropy and peak value for every sample\n",
    "  firstTrainXEntropies = []\n",
    "  firstTrainXPeakValues = []\n",
    "  for sample in firstTrainXPredictions:\n",
    "    #calculate entropy\n",
    "    sampleEntropy = entropy(sample)\n",
    "    #calculate peak value\n",
    "    probSorted = sorted(sample)\n",
    "    peakValue = probSorted[0]/probSorted[1]\n",
    "\n",
    "    firstTrainXEntropies.append(sampleEntropy)\n",
    "    firstTrainXPeakValues.append(peakValue)\n",
    "\n",
    "  #set NANs to 0\n",
    "  firstTrainXPeakValues = np.array(firstTrainXPeakValues)\n",
    "  firstTrainXPeakValues[np.isnan(firstTrainXPeakValues)] = 0\n",
    "  #calculate mean of entropy and peak value\n",
    "  meanEntropy = np.mean(firstTrainXEntropies)\n",
    "  meanPeakValue = np.mean(firstTrainXPeakValues)\n",
    "\n",
    "  #entropy and peak value hyperparameter\n",
    "  entropyVal = perEntropy*meanEntropy\n",
    "  peakVal = perPeak*meanPeakValue\n",
    "\n",
    "  #obtain samples that were correctly predicted and fall under the threshold for entropy and peak value\n",
    "  for i in range(len(firstTrainXPredictions)):\n",
    "    probDist = firstTrainXPredictions[i]\n",
    "    predictedClass = np.argmax(probDist)\n",
    "\n",
    "    #if confident add to list\n",
    "    if predictedClass == firstTrainY[i] and firstTrainXEntropies[i] <= entropyVal and firstTrainXPeakValues[i] > peakVal:\n",
    "      newTrainX.append(firstTrainX[i])\n",
    "      newTrainY.append(firstTrainY[i])\n",
    "      confidentIndexes.append(beforeSplitIndexes[i])\n",
    "\n",
    "\n",
    "\n",
    "  #find confident samples from unused training set\n",
    "  #obtain probability distribution of classes for each sample after the split and calculate its entropy\n",
    "  #make predictions\n",
    "  secondTrainXPredictions = model.predict(secondTrainX)\n",
    "  #find entropy and peak value for every sample\n",
    "  secondTrainXEntropies = []\n",
    "  secondTrainXPeakValues = []\n",
    "  for sample in secondTrainXPredictions:\n",
    "    #calculate entropy\n",
    "    sampleEntropy = entropy(sample)\n",
    "    #calculate peak value\n",
    "    probSorted = sorted(sample)\n",
    "    peakValue = probSorted[0]/probSorted[1]\n",
    "\n",
    "    secondTrainXEntropies.append(sampleEntropy)\n",
    "    secondTrainXPeakValues.append(peakValue)\n",
    "\n",
    "  #set NANs to 0\n",
    "  secondTrainXPeakValues = np.array(secondTrainXPeakValues)\n",
    "  secondTrainXPeakValues[np.isnan(secondTrainXPeakValues)] = 0\n",
    "\n",
    "  #calculate mean of entropy and peak value\n",
    "  meanEntropy = np.mean(secondTrainXEntropies)\n",
    "  meanPeakValue = np.mean(secondTrainXPeakValues)\n",
    "\n",
    "  #entropy and peak value hyperparameter\n",
    "  entropyVal = perEntropy*meanEntropy\n",
    "  peakVal = perPeak*meanPeakValue\n",
    "\n",
    "  #obtain samples that were correctly predicted and fall under the threshold for entropy and peak value\n",
    "  for i in range(len(secondTrainXPredictions)):\n",
    "    probDist = secondTrainXPredictions[i]\n",
    "    predictedClass = np.argmax(probDist)\n",
    "\n",
    "    #if confident add to list\n",
    "    if predictedClass == secondTrainY[i] and secondTrainXEntropies[i] <= entropyVal and secondTrainXPeakValues[i] > peakVal:\n",
    "      newTrainX.append(secondTrainX[i])\n",
    "      newTrainY.append(secondTrainY[i])\n",
    "      confidentIndexes.append(afterSplitIndexes[i])\n",
    "\n",
    "  return newTrainX, newTrainY, confidentIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kozeF08fFyDu"
   },
   "outputs": [],
   "source": [
    "#find out how much of corrupted test data the model can correctly predict\n",
    "def accuracyWithMislabeled(ransac_model, testX, testY, testYMislabeled):\n",
    "  predictions = ransac_model.predict(testX)\n",
    "  correctlyPredicted = 0\n",
    "  normalCount = 0\n",
    "  correctlyIdentified = 0\n",
    "  corruptedCount = 0\n",
    "  for i in range(len(testY)):\n",
    "    #obtain prediction\n",
    "    prediction = np.argmax(predictions[i])\n",
    "\n",
    "    #check if not corrupted and correctly predicted\n",
    "    if testYMislabeled[i] == testY[i]:\n",
    "      normalCount+=1\n",
    "      if prediction == testY[i]:\n",
    "        correctlyPredicted += 1\n",
    "    #check if corruped and correctly identified\n",
    "    elif testYMislabeled[i] != testY[i]:\n",
    "      corruptedCount += 1\n",
    "      if prediction == testY[i]:\n",
    "        correctlyIdentified +=1\n",
    "\n",
    "  return correctlyPredicted, normalCount, correctlyIdentified, corruptedCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OhU6W0utRcAc",
    "outputId": "eac8eee0-15e4-4ad3-f9e6-8b97828fa65f"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\n",
    "#Normalize pixel values to be between 0 and 1\n",
    "trainX, testX = trainX / 255.0, testX / 255.0\n",
    "\n",
    "#flatten the label values\n",
    "trainY, testY = trainY.flatten(), testY.flatten()\n",
    "\n",
    "#corrupt data\n",
    "noisePercentage = 0.25\n",
    "trainYMislabeled, testYMislabeled = corruptData(trainY, testY, noisePercentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbN-krTKiQcu",
    "outputId": "bb433df7-4bf9-450d-86af-6c7ea19ecdcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 35ms/step - loss: 1.2711 - accuracy: 0.7181\n",
      "0.7181000113487244\n"
     ]
    }
   ],
   "source": [
    "cleanModel = load_model('CleanModelTraining/ransac_clean.h5')\n",
    "upperBoundAccuracy = cleanModel.evaluate(testX, testY)[1]\n",
    "\n",
    "print(upperBoundAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gBQTSX18GP7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 10\n",
      "Epoch 1/20\n",
      " 275/1094 [======>.......................] - ETA: 2:08 - loss: 2.6063 - accuracy: 0.2460"
     ]
    }
   ],
   "source": [
    "#collect best indexes over multiple models\n",
    "bestIndexes = list(range(len(trainX)))\n",
    "for i in range(5):\n",
    "  #split data\n",
    "  splitPercentage = .7\n",
    "  firstTrainX, firstTrainY, secondTrainX, secondTrainY, beforeSplitIndexes, afterSplitIndexes = splitTrainingData(trainX, trainYMislabeled, splitPercentage)\n",
    "\n",
    "  #train model used to identify confident samples\n",
    "  confidenceModel = trainModel(firstTrainX, firstTrainY, 1)\n",
    "  percentageOfEntropy = [0.5,1,2,3]\n",
    "  percentageOfPeak = [2,1.5,1,.5]\n",
    "  for j in range(len(percentageOfEntropy)):\n",
    "    perEntropy = percentageOfEntropy[j]\n",
    "    perPeak = percentageOfPeak[j]\n",
    "    \n",
    "    #find samples that this model is confident on\n",
    "    newTrainX, newTrainY, confidentIndexes = makeConfidentTrainingSets(confidenceModel, firstTrainX, firstTrainY, secondTrainX, secondTrainY, perEntropy, perPeak, beforeSplitIndexes, afterSplitIndexes)\n",
    "\n",
    "    #add 1 to every confident image\n",
    "    for index in confidentIndexes:\n",
    "      bestIndexes[index]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN6fYEkT9NDS"
   },
   "outputs": [],
   "source": [
    "#make new datasets for the most confident samples\n",
    "bestTrainX=[]\n",
    "bestTrainY=[]\n",
    "\n",
    "#sort and preserve index\n",
    "bestSorted = np.argsort(bestIndexes)\n",
    "\n",
    "#calculate number of samples to user\n",
    "numberCertain = int(0.5 * len(bestIndexes))\n",
    "\n",
    "#take certain samples\n",
    "for i in range(numberCertain):\n",
    "  bestTrainX.append(trainX[bestSorted[i]])\n",
    "  bestTrainY.append(trainYMislabeled[bestSorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MQLJBTKXRxSw",
    "outputId": "c3d3d1f1-ee07-45da-ada7-c30b02269e56"
   },
   "outputs": [],
   "source": [
    "#run experiments\n",
    "#train a new model on these confident samples\n",
    "ransacModel = trainModel(bestTrainX, bestTrainY, 1)\n",
    "\n",
    "#calculate accuracy of this model in identifying corrupted samples\n",
    "correctlyPredicted, normalCount, correctlyIdentified, corruptedCount = accuracyWithMislabeled(ransacModel, testX, testY, testYMislabeled)\n",
    "\n",
    "#add performance\n",
    "modelPerformance = (correctlyPredicted, normalCount, correctlyIdentified, corruptedCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "id": "YG3lr6unwnYK",
    "outputId": "1189c288-270c-4932-bfc6-d63c4cc07f19"
   },
   "outputs": [],
   "source": [
    "print(\"This model was able to correctly predict\",modelPerformance[0],\"samples out of\",modelPerformance[1])\n",
    "print(\"This model was able to correctly identify\",modelPerformance[2],\"mislabeled samples out of\",modelPerformance[3])\n",
    "print(\"Adding in the correctly identified mislabeled samples this model had an accuracy of\",((modelPerformance[0]+modelPerformance[2])/len(testY)))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNWJ3wfrngO4rSe3J2tz8Qe",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "RANSAC_v2 Identifier Accuracy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
