# -*- coding: utf-8 -*-
"""RANSAC_v2 Identifier Accuracy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r_F2EOa0JUUIxhOpom2NkIscwXnrWzQl
"""
import sys
sys.path.append('../')
from cifar10_ransac_utils import *
from scipy.stats import entropy
import numpy as np
import random
from tensorflow import keras
import matplotlib.pyplot as plt
import tensorflow as tf
import os
from ResNet import ResNet20ForCIFAR10
from tensorflow.keras import losses
from tensorflow.keras.callbacks import LearningRateScheduler
import itertools



os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "6"  # (xxxx is your specific GPU ID)

# method to add noisy labels to data


def corruptData(trainY, noisePercentage):
    # create copies of labels
    copyTrainY = trainY.copy()

    # calculate number of samples to be made noisy
    numberNoisyTrain = int(noisePercentage * len(copyTrainY))

    # generate indexes to swap
    trainYSwitchIndexes = random.sample(
        range(0, len(copyTrainY)), numberNoisyTrain)

    # generate new classes not equal to original for training and switch class
    for i in range(len(trainYSwitchIndexes)):
        label = random.choice(range(10))
        # find label that isn't the same
        while label == np.argmax(trainY[trainYSwitchIndexes[i]]):
            label = random.choice(range(10))
        # switch label
        newLabel = np.zeros(10)
        newLabel[label] = 1
        copyTrainY[trainYSwitchIndexes[i]] = np.array(newLabel)

    return copyTrainY


def trainModel(X, Y):
    # compile a model
    weight_decay = 1e-4
    lr = 1e-1
    num_classes = 10
    model = ResNet20ForCIFAR10(input_shape=(
        32, 32, 3), classes=num_classes, weight_decay=weight_decay)
    opt = tf.keras.optimizers.SGD(lr=lr, momentum=0.9, nesterov=False)
    model.compile(optimizer=opt,
                  loss=losses.categorical_crossentropy,
                  metrics=['accuracy'])

    def lr_scheduler(epoch):
        new_lr = lr
        if epoch <= 21:
            pass
        elif epoch > 21 and epoch <= 37:
            new_lr = lr * 0.1
        else:
            new_lr = lr * 0.01
        print('new lr:%.2e' % new_lr)
        return new_lr

    reduce_lr = LearningRateScheduler(lr_scheduler)

    # fit model
    model.fit(X, Y, epochs=50,
              batch_size=128, callbacks=[reduce_lr])

    return model


def makeConfidentTrainingSets(model, corTrainX, corTrainY, entropyThreshold, peakThreshold, trainY):
    sampleArray = []
    # find confident samples from first training set
    # obtain probability distribution of classes for each sample after the split and calculate its entropy
    # make predictions
    predictions = model.predict(corTrainX)
    # find entropy for every sample and decide if confident
    for i in range(len(predictions)):
        sample = predictions[i]
        # get classification
        predictedClass = np.argmax(sample)
        # calculate entropy
        sampleEntropy = entropy(sample)

        # calculate peak value
        probSorted = sorted(sample)
        probSorted = probSorted[::-1]
        # sum all prob except max
        probSum = 0
        for j in range(1, len(probSorted)):
            probSum += probSorted[j]
        peakValue = probSorted[0]/probSum

        if np.isnan(peakValue) or peakValue > 1000:
            peakValue = 1000

        confident = 0
        if predictedClass == np.argmax(corTrainY[i]) and sampleEntropy <= entropyThreshold and peakValue >= peakThreshold:
            confident = 1

        # determine how accurate classification was

        classificationScore = 0

        if predictedClass != np.argmax(corTrainY[i]) and predictedClass != np.argmax(trainY[i]):
            classificationScore = 0
        elif predictedClass == np.argmax(corTrainY[i]) and predictedClass != np.argmax(trainY[i]):
            classificationScore = 1
        elif predictedClass != np.argmax(corTrainY[i]) and predictedClass == np.argmax(trainY[i]):
            classificationScore = 2
        elif predictedClass == np.argmax(corTrainY[i]) and predictedClass == np.argmax(trainY[i]):
            classificationScore = 3

        sampleData = [predictedClass, sampleEntropy,
                      peakValue, confident, classificationScore]
        sampleArray.append(sampleData)

    return sampleArray


# get data
cifar10_data = CIFAR10Data()
trainX, trainY, testX, testY = cifar10_data.get_data(subtract_mean=True)

# corrupt data
noisePercentage = 0.1
trainYMislabeled = corruptData(trainY, noisePercentage)

# print(upperBoundAccuracy)

print("Num GPUs Available: ", len(
    tf.config.experimental.list_physical_devices('GPU')))

# collect best indexes over multiple models
featureVector = []
for p in range(5):
    # select subset of data to train on
    # calculate number of samples to be added to subset
    numberTrain = int(0.8 * len(trainX))

    # generate indexes to use
    trainIndexes = random.sample(
        range(0, len(trainX)), numberTrain)

    # add subset samples to correct arrays
    subsetTrainX = []
    subsetTrainY = []
    for index in trainIndexes:
        subsetTrainX.append(trainX[index])
        subsetTrainY.append(trainYMislabeled[index])
    subsetTrainX = np.array(subsetTrainX)
    subsetTrainY = np.array(subsetTrainY)

    # train model used to identify confident samples
    confidenceModel = trainModel(subsetTrainX, subsetTrainY)
    # from cross validation
    entropyThreshold = .1
    peakThreshold = 400

    # find samples that this model is confident on
    sampleArray = makeConfidentTrainingSets(
        confidenceModel, trainX, trainYMislabeled, entropyThreshold, peakThreshold, trainY)

    # add iteration data to feature vector
    featureVector.append(sampleArray)

# we first want to visualize the feature vector over the space

# lets examine consistency and noisy data
# lets examine that data points that have consistent/inconsistent labels

# consistentAndConfident = []
# inconsistentAndConfident = []
# consistentAndUnconfident = []
# inconsistentAndUnconfident = []

consistentAndClean = []
consistentAndNoisy = []
inconsistentAndClean = []
inconsistentAndNoisy = []

# iterate through each samples iteration data

for i in range(len(trainX)):
    # get iteration data
    iterData = []
    for iter in featureVector:
        iterData.append(iter[i])

    # add up confidence, entropy, and peak and check if label is consistent
    confidence = 0
    ent = 0
    peak = 0
    curLabel = iterData[0][0]
    consistent = True

    # labels = [0,0,0,0,0,0,0,0,0,0]

    for it in iterData:
        confidence += it[3]
        ent += it[1]
        peak += it[2]

        # labels[it[0]] += 1

        if it[0] != curLabel:
            consistent = False

    # determine confidence
    confident = confidence > (len(featureVector)/2)
    # calculate avg entropy and peak
    avgEnt = ent/len(featureVector)
    avgPeak = peak/len(featureVector)

    # ensembleLabel = np.argmax(labels)

    noisy = (np.argmax(trainY[i]) == np.argmax(trainYMislabeled[i]))

    pair = [avgEnt, avgPeak]

    # add to apropriate array
    if consistent and noisy:
        consistentAndNoisy.append(pair)
    elif consistent and not noisy:
        consistentAndClean.append(pair)
    elif not consistent and noisy:
        inconsistentAndNoisy.append(pair)
    elif not consistent and not noisy:
        inconsistentAndClean.append(pair)

plt.scatter(*zip(*consistentAndNoisy),
            label='Consistent and Noisy')
plt.xlim([0, 1.2])
plt.ylim([0, 1005])
plt.xlabel("Average Entropy over Iterations")
plt.ylabel("Average Peak Value over Iterations")
plt.legend(bbox_to_anchor=(1.05, 1))
plt.title('Consistent and Noisy Samples')
plt.savefig('consistentAndNoisy.png')
plt.close()

plt.scatter(*zip(*consistentAndClean),
            label='Consistent and Clean')
plt.xlim([0, 1.2])
plt.ylim([0, 1005])
plt.xlabel("Average Entropy over Iterations")
plt.ylabel("Average Peak Value over Iterations")
plt.legend(bbox_to_anchor=(1.05, 1))
plt.title('Consistent and Clean Samples')
plt.savefig('consistentAndClean.png')
plt.close()

plt.scatter(*zip(*inconsistentAndNoisy),
            label='Inconsistent and Noisy')
plt.xlim([0, 1.2])
plt.ylim([0, 1005])
plt.xlabel("Average Entropy over Iterations")
plt.ylabel("Average Peak Value over Iterations")
plt.legend(bbox_to_anchor=(1.05, 1))
plt.title('Inconsistent and Noisy Samples')
plt.savefig('inconsistentAndNoisy.png')
plt.close()

plt.scatter(*zip(*inconsistentAndClean),
            label='Inconsistent and Clean')
plt.xlim([0, 1.2])
plt.ylim([0, 1005])
plt.xlabel("Average Entropy over Iterations")
plt.ylabel("Average Peak Value over Iterations")
plt.legend(bbox_to_anchor=(1.05, 1))
plt.title('Inconsistent and Clean Samples')
plt.savefig('inconsistentAndClean.png')
plt.close()