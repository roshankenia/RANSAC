{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RANSAC_CLEAN_TRAINING.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJPWrDfu2FGiNsWMYO0rUt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshankenia/RANSAC/blob/main/Clean%20Model%20Training/RANSAC_CLEAN_TRAINING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "coAgHZS-u52w"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, Conv2D, GlobalMaxPooling2D, MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\n",
        "#Normalize pixel values to be between 0 and 1\n",
        "trainX, testX = trainX / 255.0, testX / 255.0\n",
        "\n",
        "#flatten the label values\n",
        "trainY, testY = trainY.flatten(), testY.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRxqbwZvySz1",
        "outputId": "bbde27c9-1f46-4596-b2f7-039f2df1d31c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 5s 0us/step\n",
            "170508288/170498071 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first train a clean model on clean data to get an upperbound\n",
        "\n",
        "# number of classes\n",
        "K = 10\n",
        "\n",
        "# calculate total number of classes\n",
        "# for output layer\n",
        "print(\"number of classes:\", K)\n",
        "\n",
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=trainX[0].shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "cleanModel = Model(i, x)\n",
        "\n",
        "# model description\n",
        "# model.summary()\n",
        "\n",
        "# Compile\n",
        "cleanModel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit\n",
        "r = cleanModel.fit(trainX, trainY, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLcsKGgNxUzE",
        "outputId": "5f17e59e-fe3e-42d7-db6d-422427485f8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of classes: 10\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 21s 7ms/step - loss: 1.4315 - accuracy: 0.5145\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0242 - accuracy: 0.6427\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8451 - accuracy: 0.7052\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6835 - accuracy: 0.7600\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5547 - accuracy: 0.8038\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4476 - accuracy: 0.8443\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3597 - accuracy: 0.8766\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3072 - accuracy: 0.8944\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2602 - accuracy: 0.9115\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2251 - accuracy: 0.9246\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2014 - accuracy: 0.9330\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1823 - accuracy: 0.9394\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1636 - accuracy: 0.9464\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1452 - accuracy: 0.9525\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1367 - accuracy: 0.9552\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1298 - accuracy: 0.9581\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1241 - accuracy: 0.9595\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1104 - accuracy: 0.9635\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1078 - accuracy: 0.9655\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0943 - accuracy: 0.9694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "cleanModel.save('ransac_clean.h5')"
      ],
      "metadata": {
        "id": "-2cGilz9xUxb"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}